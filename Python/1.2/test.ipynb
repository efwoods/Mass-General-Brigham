{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, argparse, bs4, requests, re, textwrap\n",
    "\n",
    "url = 'https://www.twitch.tv/directory'\n",
    "\n",
    "tags = ['HTML', 'title', 'head', 'body', 'p', 'b', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method: extract\n",
    "Input:\n",
    "    url: The url to be parsed\n",
    "    tags: a list of tags to be parsed from the url; \n",
    "    tags are treated as case insensitive, and stripped of '<!/>' characters\n",
    "Output:\n",
    "    list_of_extracted_data: \n",
    "        A list of strings found within each tag; \n",
    "        Contains all text found within tags nested inside the requested tag;\n",
    "        \n",
    "        Assumptions:\n",
    "            If a tag does not contain text within the tag \n",
    "                or within any of the tags nested inside of the requested tag,\n",
    "                the value stored inside the list of extracted data will be ''.\n",
    "            If a tag is not found in the html document, \n",
    "                no content will be added to the list_of_extracted_data for that tag.\n",
    "\n",
    "'''\n",
    "\n",
    "def extract(url, tags):\n",
    "    res = requests.get(url);\n",
    "    res.raise_for_status();\n",
    "    soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "    print('Number of tags: {}'.format(len(tags)))\n",
    "    list_of_extracted_data = []\n",
    "    for unique_tag_index in range(0,len(tags)):\n",
    "        print('tag #{}:'.format(unique_tag_index+1))\n",
    "        regex_search_string = \"^\" + tags[unique_tag_index].strip('<!/>') + \"$\"\n",
    "        print('regex search string: {}'.format(regex_search_string))\n",
    "        unique_tag_list = soup.find_all(re.compile(regex_search_string,re.I))\n",
    "        print(unique_tag_list)\n",
    "        print('result length: {}'.format(len(unique_tag_list)))\n",
    "        for tag_data in range(0,len(unique_tag_list)):\n",
    "            list_of_extracted_data.append(unique_tag_list[tag_data].text);\n",
    "    print('list_of_extracted_data: {}'.format(list_of_extracted_data))\n",
    "    return list_of_extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2645829838.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [211]\u001b[0;36m\u001b[0m\n\u001b[0;31m    parser.add_argument('-u','--url', type=str required=True)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Extract', formatter_class=argparse.RawTextHelpFormatter)\n",
    "    parser.add_argument('-u','--url', type=str, required=True)\n",
    "    parser.add_argument('-t','--tags',nargs='+', required=True, \n",
    "       help=textwrap.dedent('''\\\n",
    "       Method: extract\n",
    "Input:\n",
    "    url: The url to be parsed\n",
    "    tags: a list of tags to be parsed from the url; \n",
    "    tags are treated as case insensitive, and stripped of '<!/>' characters\n",
    "Output:\n",
    "    list_of_extracted_data: \n",
    "        A list of strings found within each tag; \n",
    "        Contains all text found within tags nested inside the requested tag;\n",
    "        \n",
    "        Assumptions:\n",
    "            If a tag does not contain text within the tag \n",
    "                or within any of the tags nested inside of the requested tag,\n",
    "                the value stored inside the list of extracted data will be ''.\n",
    "            If a tag is not found in the html document, \n",
    "                no content will be added to the list_of_extracted_data for that tag.'''))\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    result_l = extract(url, tags);\n",
    "    print(result_l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
